---
title: "NBA Data Wrangling using IBM Data Science Experience (DSX)"
authors: "Catherine Cao, Dustin VanStee"
date: "September 17, 2016"
---

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

> Have you ever wanted predict outcomes of NBA games in real time as the games are occurring?  This webpage is part 1 or a 2 part series that will describe the methods you can use to build your own prediction model.  We will leverage IBM's Data Science Experience environment with Rstudio to build linear and logistic regression models using R and Spark.  

![datascience.ibm.com](https://raw.githubusercontent.com/dustinvanstee/nba-rt-prediction/master/dsx.png)

As a final step, we deploy an app in IBM's Bluemix using NodeJS.  The site is live and lets you interact with the model that was built using the analysis from the R. 

![169.55.24.28:6001](https://raw.githubusercontent.com/dustinvanstee/nba-rt-prediction/master/nodejsapp.png)

>This site holds the live hosted website running the models from the analysis
http://169.55.24.28:6001/

>All the source for this demo including the HOWTO is located on GitHub. 
https://github.com/dustinvanstee/nba-rt-prediction

>Lets get started!
```{r global_options, echo = FALSE, include = FALSE}
options(width = 999)
knitr::opts_chunk$set(message = FALSE,
                      cache = FALSE, tidy = FALSE, size = "small")
```

# Import libraries

```{r message = FALSE}

packages <- c("dplyr", "plyr", "chron", "scatterD3", "plotly", "RCurl", "rmarkdown")

if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))  
}

library(rmarkdown)
library(RCurl)
library(dplyr)
library(plyr)
library(chron)
library(scatterD3)
library(plotly)

```


***

# Download Game Score Data from Github into Dataframe
```{r label = "test", message = FALSE}
#Curl data from Github
nba_scores_lines <- readLines(textConnection(getURL("https://raw.githubusercontent.com/dustinvanstee/nba-rt-prediction/master/scores_nba.test.dat")))

# Split CSV line array into tokens, and load them into dataframe
nba_scores_DF <- as.data.frame(do.call(rbind, strsplit(nba_scores_lines, ",")), stringsAsFactors=FALSE)

# Since there isnt header in the data set, specify the column metadata
colnames(nba_scores_DF) <- c("dateOrig","ts","teamlonga", "scorea", "teamlongb", "scoreb", "timestring", "timeleft", "gameid")

# Apply Types to the data  
nba_scores_DF2 <- transform(nba_scores_DF, 
                            dateOrig = as.Date(dateOrig),
                            ts = as.character(ts),
                            teamlonga = as.character(teamlonga),
                            scorea = as.numeric (scorea),
                            teamlongb = as.character(teamlongb),
                            scoreb = as.numeric (scoreb),
                            timestring = as.character(timestring),
                            timeleft = as.numeric(timeleft),
                            gameid = as.character(gameid))
```

***

# Inspect Historical score data

> This data is the raw input that contains a record for each update of the game.  Each game has approximately ~120 data points from start to finish.  Games were sampled on 1 minute intervals.
The data has some errors and redundancies that will be removed.  The first step needed is to seperate the in game scores and the final scores.  The final score outcome will end up being the value that will try to be predicted , and therefore must be appended to every in game score.

```{r}
# NAs (not available) are introduced because the raw data has invalid data points, so remove these observations
rtscoresAndFinalDF <- na.omit(nba_scores_DF2)

# Print the dimensions of the data.  Rows are the number of individual score data points.
dim(rtscoresAndFinalDF) #16746     9

# Take a look at the first few rows of the dataframe
head(rtscoresAndFinalDF)

# Final Scores
head(filter(rtscoresAndFinalDF, grepl("FINAL", timestring)))

# Scores from 1st quarter
head(filter(rtscoresAndFinalDF, grepl("1ST", timestring)))

```
***

# Utility Function to Map Team Names and Convert Dates

>  The odds data and score data files had a different naming conventions for the teams.  This function will be used to map all long team names into 3 letter acronym

```{r}
# Function to turn long team name to short
teamMap <- function(x) {
  tnames <- data.frame(
    long = as.factor(c("Atlanta", "Boston", "Brooklyn", "Charlotte", "Chicago", 
                       "Cleveland", "Dallas", "Denver", "Detroit", "Golden State", 
                       "Houston","Indiana", "LA Clippers", "LA Lakers", "Memphis", 
                       "Miami", "Milwaukee", "Minnesota", "New Orleans", "New York",
                       "Oklahoma City", "Orlando", "Philadelphia", "Phila.", "Phoenix",
                       "Portland",  "Sacramento", "San Antonio", "Toronto", "Utah", "Washington")),
    short = as.factor(c("atl", "bos", "bkn", "cha", "chi",
                        "cle", "dal", "den", "det", "gst",
                        "hou", "ind", "lac", "lal", "mem",
                        "mia", "mil", "min", "nor", "nyk",
                        "okc", "orl", "phi", "phi", "pho",
                        "por", "sac", "san", "tor", "uta", "wsh"))
  )
  df_x <- data.frame(long=x)
  short <- tnames$short[match(df_x$long, tnames$long)]
  return(short)
  
}

# Function to convert 3-character month to 2-digit numeric month
monthMap <-function(x) {
  a <-data.frame(
    str = as.factor(c("Jan", "Feb", "Mar", "Apr", "May", 
                      "Jun", "Jul", "Aug", "Sep", "Oct", 
                      "Nov", "Dec")),
    num = as.factor(c("01", "02", "03", "04", "05",
                      "06", "07", "08", "09", "10",
                      "11", "12"))
  )
  df_x <- data.frame(str=x)
  num <- a$num[match(df_x$str, a$str)]
  return(num) 
}

# Unique key for each game consists of date, home team, away team.  For games that span multiple days due to 
# continuing through midnight, date logic is required to adjust some of the score data. 

# Inputs : input date, timestamp 
# Retuns : adjusted date

# If time is midnight -> 3am EST, then adjust
dateadjustudf <- function(datein, tsin){
                   newdate <- c()
                   for (i in 1:length(tsin)){
                      if (grepl("^0[0-3]", tsin[i])) {
                          newdate[i] = datein[i] - 1
                      } else {
                          newdate[i] = datein[i]
                      }
                    }
                   return(newdate)
                  }
```

***


***

# Preprocess the In Game and Final Score Data
> Remove overtime, add keys for joins, and perform date transformations 
```{r}
# Remove Overtime games from this analysis
rtscoresAndFinalDF <- filter(rtscoresAndFinalDF, !grepl(".*OT.*", timestring))
#16626

# Create short 3 character team names
rtscoresAndFinalDF$teama <- teamMap(rtscoresAndFinalDF$teamlonga)
rtscoresAndFinalDF$teamb <- teamMap(rtscoresAndFinalDF$teamlongb)

# Add a score differential Column 
rtscoresAndFinalDF$scorea_scoreb <- rtscoresAndFinalDF$scorea - rtscoresAndFinalDF$scoreb

# Transform the Date.  This is for games that spanned multiple days. 
# Games adjusted to the day they started on.
rtscoresAndFinalDF$date <-  dateadjustudf(rtscoresAndFinalDF$dateOrig, rtscoresAndFinalDF$ts)
rtscoresAndFinalDF$date <- as.Date(rtscoresAndFinalDF$date, origin = "1970-01-01")

# Create a key to join with odds data later.  Key = date.teama.teamb
for (i in 1:nrow(rtscoresAndFinalDF)){
  rtscoresAndFinalDF$key[i] <- paste0(rtscoresAndFinalDF$date[i], ".", rtscoresAndFinalDF$teama[i], ".", rtscoresAndFinalDF$teamb[i])
}

#rtscoresAndFinalDF$key2 <- paste(rtscoresAndFinalDF$date, rtscoresAndFinalDF$teama, rtscoresAndFinalDF$teamb, sep=".")

```

***
# Separate The In Game And Final Data From One Common Dataframe To Two Dataframes
> Based on the way the data was sampled, both i ngame scores and final scores are written as seperate records to the same file. For building predictive models, each in game score needs to have the final score appended to it.  After the data is seperated, a few extra features will be added to the in game scores, and then the in game and final scores will be joined.

```{r}
# Create Final Score DF
# filter out any score that has FINAL
finalscoresDF <- filter(rtscoresAndFinalDF, grepl("FINAL", timestring))

# Rename some columns so that join later doesnt have name overlaps
finalscoresDF$fscorea <- finalscoresDF$scorea
finalscoresDF$fscoreb <- finalscoresDF$scoreb

# Create final score difference
finalscoresDF$fscorea_fscoreb <- finalscoresDF$fscorea - finalscoresDF$fscoreb
finalscoresDF$fscoreb_fscorea <- finalscoresDF$fscoreb - finalscoresDF$fscorea


# Add a Win/loss column Win = 1, Loss = 0
for (i in 1 : nrow(finalscoresDF)){
  if (finalscoresDF$fscorea_fscoreb[i] > 0){
    finalscoresDF$home_win[i] <- 0
    finalscoresDF$away_win[i] <- 1
  } else {
    finalscoresDF$home_win[i] <- 1
    finalscoresDF$away_win[i] <- 0
  }
}


#################################################################################################################
# Create In Game score DF and remove some problematic data points.
# Remove halftime records and these other cases as  datasource doesnt always update the quarter change well
rtscoresDF <- filter(rtscoresAndFinalDF, !grepl('HALF', timestring), !grepl('FINAL', timestring),
                   timestring != "(12:00 IN 1ST)" ,
                   timestring != "(12:00 IN 2ND)" , 
                   timestring != "(12:00 IN 3RD)" ,
                   timestring != "(12:00 IN 4TH)" ,  
                   timestring != "(END OF 1ST)" ,
                   timestring != "(END OF 2ND)" , 
                   timestring != "(END OF 3RD)" ,
                   timestring != "(END OF 4TH)" )


# Create in game score difference
rtscoresDF$scorea_scoreb <-  rtscoresDF$scorea - rtscoresDF$scoreb
rtscoresDF$scoreb_scorea <-  rtscoresDF$scoreb - rtscoresDF$scorea


# Create a game PCT complete and PCT left indictor
rtscoresDF$pct_complete <- (((rtscoresDF$timeleft * -1) + 48 )/48.0)*100
rtscoresDF$pct_left <- 100 - rtscoresDF$pct_complete

# Create some custom features that weight score difference more as the game comes near to finish 
# These features were added as initial models did not fit the end of game well.
rtscoresDF$cf1 <- (1/((rtscoresDF$pct_left/25 + .01)^.5)) * rtscoresDF$scoreb_scorea
rtscoresDF$cf2 <- (1/((rtscoresDF$pct_left/2.0 + .01)^1.3))*rtscoresDF$scoreb_scorea

```

***

# Custom Feature Explanation

> After building the initial model without custom features, the logistic model was not adjusting the probabilities well at the end of the games. There some examples when there was 0 minutes left in the game, and yet the logistic model was giving a 70% chance of victory for a team. This was due to the fact that the original features were not fitting the end of game very well. To fix this, a custom feature was added that takes the score difference and amplifies it as the score nears the end of the game. This feature dominates at the end of games and helps fit the data at the end of games.

# Score difference as a function of % Complete
```{r, out.width = 'auto'}
# subset a dataframe for scatterplot
# spreader <- filter(rtscoresDF, pct_complete < 95)

# draw interactive scatter plot
scatterD3(x = rtscoresDF$pct_complete, y = rtscoresDF$scoreb_scorea, col_var = rtscoresDF$key, xlab = "% of Game Complete", ylab = "score difference", xlim = c(0,100),  point_size = 10)
```

***

# Custom score difference spreader feature
```{r, out.width = 'auto'}
scatterD3(x = rtscoresDF$pct_complete, y = rtscoresDF$cf1, col_var = rtscoresDF$key, xlab = "% of Game Complete", ylab = "score difference amplified", xlim = c(0,100), ylim = c(-20,20),  point_size = 10)
```
***

# Print out a few records from Final and In game dataframes
```{r, echo = FALSE}
# Some Printouts .....
print("Final scores data frame")
head(finalscoresDF)
paste0("Total Games = ", nrow(finalscoresDF))
print("In game scores data frame")
head(rtscoresDF)
paste0("Total Number of rt score records = ", nrow(rtscoresDF))
```


# Inspect Odds Data
> How to Interpret the Raw Odds data


    
    Example Golden State -12.5 O (207.0) -125.0 | Detroit 12.5 U (207.0) 145.0
    The away team is listed first, and the home team is second
    Here Golden State is a 12.5 pt favorite to win.  The over under is in parentheses (207) and is the 50/50 line between teams sum of scores
    being above/below that line.  
    Finally the -125 / +145 numbers are whats known at the moneyline odds. 
        A negative number means you need to bet 125$ to get a 100$ payout
        A positive number means you need to bet 100$ to get a 145$ payout
***

# Load in Raw Odds Data and Parse into Dataframe
```{r}
xml <- readLines(textConnection(getURL("https://raw.githubusercontent.com/dustinvanstee/nba-rt-prediction/master/nbaodds_042516.xml")))

# use regular expression to catch info we need
odds <- lapply(xml, function(x) substr(x, regexpr(">", x) + 1, regexpr("/", x) - 2))
odds_split <- lapply(odds, function(x) unlist(strsplit(x, " ")))

# get teamlonga
teamlonga_0 <- lapply(odds_split, function(x) paste(x[1], x[2]))
teamlonga <- lapply(teamlonga_0, function(x){
  if (regexpr("[0-9|-]", x) > -1) {
    substr(x, 1, regexpr("[0-9|-]", x)-2) 
  } else{
    x 
  }
})

# get teamlongb
teamlongb_0 <- lapply(odds_split, function(x) paste(x[7],x[8], x[9]))
teamlongb_1 <- lapply(teamlongb_0, function(x){
  if (regexpr("[0-9]", x) > -1) {
    substr(x, regexpr("[A-Za-z]", x), regexpr("[0-9-]", x)-2) 
  } else{
    x 
  }
})

teamlongb <- lapply(teamlongb_1, function(x){
  if (regexpr("|", x) > -1){
    substr(x, regexpr("[A-Za-z]", x), nchar(x))
  } else {
    x
  }
})

# teamaspread
teamaspread_0 <- lapply(odds, function(x){
  substr(x, regexpr("[0-9-]",x), regexpr("[0-9-]",x)+4)
})

teamaspread <- lapply(teamaspread_0, function(x){
  if (regexpr("[ ]", x) > 0){
    substr(x, 1, regexpr("[ ]", x)-1)
  } else {
    x
  }
})

# overunder
overunder <- lapply(odds, function(x){
  substr(x, regexpr("[(]", x) + 1, regexpr("[)]", x) - 1)
})

# teamaml
teamaml <- lapply(odds, function(x){
  substr(x,regexpr("[)]", x) + 2, regexpr("[|]", x) - 2 )
})

# teambml
teambml <- lapply(odds, function(x){
  substr(x, gregexpr("[)]", x)[[1]][2]+2, gregexpr("[(]", x)[[1]][3]-2)
})


#get date
dateStr <- lapply(odds, function(x){
  month <- substr(x, gregexpr("[(]", x)[[1]][3]+1, gregexpr("[(]", x)[[1]][3]+3)
  month_num <- monthMap(month)
  date <- substr(x, gregexpr("[(]", x)[[1]][3]+5, gregexpr("[(]", x)[[1]][3]+6)
  year <- substr(x, gregexpr("[(]", x)[[1]][3]+9, gregexpr("[(]", x)[[1]][3]+12)
  paste0(year, "-", month_num, "-", date)
})

# get short team names
teama <- lapply(teamlonga, teamMap)
teamb <- lapply(teamlongb, teamMap)

# bind all column together into dataframe

oddsDF <- na.omit(do.call(rbind, Map(data.frame, teamlonga=teamlonga, teama=teama, teamlongb=teamlongb, teamb=teamb, teamaspread=teamaspread, overunder=overunder, teamaml=teamaml, teambml=teambml, dateStr=dateStr)))

# change to right data type and create a key for join later
oddsDF$teamaspread <- as.numeric(as.character(oddsDF$teamaspread))
oddsDF$overunder <- as.numeric(as.character(oddsDF$overunder))
oddsDF$teamaml <- as.numeric(as.character(oddsDF$teamaml))
oddsDF$teambml <- as.numeric(as.character(oddsDF$teambml))

oddsDF$teama <- as.character(oddsDF$teama)
oddsDF$teamb <- as.character(oddsDF$teamb)
oddsDF$key <- paste0(oddsDF$dateStr, ".", oddsDF$teama, ".", oddsDF$teamb)
# Print the Dimensions of the data.  Currently collected 161 games
dim(oddsDF) #161  10

# add the groupby and average below because some games had odds over multiple days, and it was adding noise to the analysis

oddsDF2 <- ddply(oddsDF, c("key", "teamlonga", "teamlongb", "teama", "teamb", "dateStr"), summarise,
               teamaspread = mean(teamaspread),
               overunder = mean(overunder),
               teamaml = mean(teamaml),
               teambml = mean(teambml))

# Create a few new columns for later analysis

oddsDF2$teambspread <- oddsDF2$teamaspread * -1

oddsDF2$teama_vegas_fscore <- (oddsDF2$overunder / 2.0) - (oddsDF2$teamaspread / 2.0)

oddsDF2$teamb_vegas_fscore <- (oddsDF2$overunder / 2.0) + (oddsDF2$teamaspread / 2.0)

```

***

# Inspect some of the Odds Data
```{r}
head(oddsDF2)
paste("total home teams = ", length(unique(oddsDF2$teama)))
paste("total away teams = ", length(unique(oddsDF2$teamb)))
paste("total games collected = ", nrow(oddsDF2))
```

***
# Analyze the Odds Data

## Avg Team Away Game Spread -  ( hint < 0 means favorite)

> Here we are averaging the away spread per team.  If the bar is above the zero line, then the team is an underdog, and under the line the team is the favorite. 8 of the 32 teams were favorites on the road including Golden State and Cleveland...

```{r, out.width = 'auto'}
# visualize away spread data
avg_away_spread <- ddply(oddsDF2, c("teamlonga", "teamlongb"), summarise,
                         awayspread_avg_teamaspread = mean(teamaspread),
                         awayspread_avg_teambspread = mean(teambspread))

# away spread group by teama
away_spread_teama <- ddply(avg_away_spread, c("teamlonga"), summarise,
                           teamaspread = mean(awayspread_avg_teamaspread))
# order by teama
away_spread_teama$teamlonga <- as.character(away_spread_teama$teamlonga)
away_spread_teama <- away_spread_teama[order(away_spread_teama$teamlonga), ]

# barchart
p <- plot_ly(
  x = away_spread_teama$teamlonga,
  y = away_spread_teama$teamaspread,
  type = "bar") %>%
  layout(margin = list(l = 50, r = 50, b = 200, t = 20, pad = 4) )
p
````

***

## Avg Home Team Game Spread - (Hint > 0  means underdog)
> Here we are averaging the home spread per team.  If the bar is above the zero line, then the team is an underdog, and under the line the team is the favorite. Note here that the home teams are favored much more, with the usual suspects having a very large advantage (SAN/GST/OKC)

```{r, out.width = 'auto'}
# spread group by teamb
away_spread_teamb <- ddply(avg_away_spread, c("teamlongb"), summarise,
                           teambspread = mean(awayspread_avg_teambspread))
# order by teamb
away_spread_teamb$teamlongb <- as.character(away_spread_teamb$teamlongb)
away_spread_teamb <- away_spread_teamb[order(away_spread_teamb$teamlongb), ]


p <- plot_ly(
        x = away_spread_teamb$teamlongb,
        y = away_spread_teamb$teambspread,
        type = "bar") %>%
        layout(margin = list(l = 50, r = 50, b = 200, t = 20, pad = 4) )

p

```

***

# Join odds and final scores data.
```{r}
# Here is where   the Odds/In Games scores/ Final Scores are joined into one wholistic data set as input for Logistic/Linear regression

# Create a smaller Final Score Dataframe and prune away some columns.  Just keep the key, final score a and b, the win/loss indicator
finalslicedscoresDF <- finalscoresDF[c("key","fscorea", "fscoreb", "fscorea_fscoreb", "fscoreb_fscorea", "away_win", "home_win")]

# First Join the 2 smallest data frames ... odd and final.
gameDF <- merge(finalslicedscoresDF, oddsDF2, by = "key")
gameDF$teamlonga <- NULL
gameDF$teamlongb <- NULL
gameDF$teama <- NULL
gameDF$teamb <- NULL

# Print Out the Game Dataframe ... notice we have the odds data merged with the win loss data ....
print("gameDF")
head(gameDF)
paste("total games collected:", nrow(gameDF)) #103

```

*** 
<<<<<<< HEAD

# Lets see if there are some correlations ... Spread vs Final Score Difference 
=======
# Correlation of Spread vs Final Score Difference 
>>>>>>> origin/master
```{r, out.width = 'auto'}
# Here we show that the better a team is (negative spread, the more they are likely to win ...)

#Here the spread at the start of the game is a decent predictor regarding the end result

# Final Score Difference vs Spread  
# Top Left indicates teams with a large pos spread will lose by a wider margin
# the line should approx pass through 0,0
# lower Right indicates teams with large neg spread will win by a wider margin 

# The logistic and linear models we build will quantify this for us later!

scatterD3(x = gameDF$fscoreb_fscorea, y = gameDF$teamaspread)
```

***

# Vegas Score Prediction vs Actual Score Outcome
```{r, out.width='50%', fig.width=3, fig.height=3 }
# Here we can show another weak correlation of the vegas overunder/spread to the actual final outcome.
# vegas_fscore was calculated by taking overunder/2 +- the spread/2 to get a projection of
# the home/away teams score
# Here if the prediction and data were perfectly correlated, we would pass through the
# y=x line.  in general we follow that path
# we will see how this term plays when we dig into the linear model
# here only home team is shown, but same trend holds for away team


# Home
scatterD3(x = gameDF$teamb_vegas_fscore, y = gameDF$fscoreb); 
# Away
scatterD3(x = gameDF$teama_vegas_fscore, y = gameDF$fscorea)
```

***

# Join The Game Dataframe With The In Game Score Dataframe
```{r}
# This is the bigger merge.  Merging the odds/final score data with the in game indicators ...
lrDF <- merge(gameDF, rtscoresDF, by = "key")
print("lrDF : Logistic Regression Data Frame")
head(lrDF)

paste("total data points collected:", nrow(lrDF)) #13412

```

# Add a Few More Features
```{r}

# Add an overunder/spread adjusted projection as points are scored during the game
# I found this is a strong indicator
lrDF$teama_adj_fscore <- ((lrDF$pct_complete  * -1)/100 + 1) * lrDF$teama_vegas_fscore + lrDF$scorea
lrDF$teamb_adj_fscore <- ((lrDF$pct_complete  * -1)/100 + 1) * lrDF$teamb_vegas_fscore + lrDF$scoreb
lrDF$pfscoreb_pfscorea <- lrDF$teamb_adj_fscore - lrDF$teama_adj_fscore
```

***

# Filter Out some Data due to data quality
```{r}
# There is an issue with the data I had captured.  When a quarter transitions from 1st->2nd (etc,etc), sometime the timestring doesn't get updated properly.  Since I used the timestring to calculate the timeleft in the game, I would get some rogue data points.  
# Example, after 1 min in a game, something the two teams would have scores in the 20's, because it was really at 11 mins in the second quarter.  
# My solution was to use the final score sum, and then just scale that down to the time left in the game.  I would then compare to the sum of scores i had, and if it was significantly higher, I would remove them.  I did this by visual inspection ... 
# dfa = departure_from_avg

lrDF$dfa <- (lrDF$fscorea + lrDF$fscoreb)/48 * (lrDF$timeleft * -1 + 48) - (lrDF$scorea + lrDF$scoreb)
lrDF_filtered <- filter(lrDF, dfa > -30)
```

***

# Lets Look at some stats from joined dataframe
```{r}
summary(lrDF_filtered)
```


# Samples per Game Visualization - Data Quality check
> One improvement to the data set would involve normalizing all games to have the same number of data points per game.  Some games that ran long ended up having a lot more samples.
```{r, out.width = 'auto'}

DQ_check <- ddply(lrDF_filtered, c("key"), summarise,
                      N = length(key))
# order by N
DQ_check <- DQ_check[order(DQ_check$N),]

# plot
p <- plot_ly(
  x = DQ_check$Key,
  y = DQ_check$N,
  type = "bar")
p
```

***

# Save Out Dataframe For Further Analysis with Logistic and Linear Regression Notebooks
```{r}
# Wanted to save out the dataset at this point.  Analysis will branch into seperate work efforts for a Logistic/Linear model building
# Also drop some columns as we move on to next step !!

lrDF_final <- lrDF_filtered
lrDF_final$dateOrig <- NULL
lrDF_final$ts <- NULL
lrDF_final$teamlonga <- NULL
lrDF_final$teamlongb <- NULL
lrDF_final$timestring <- NULL
lrDF_final$gameid <- NULL
lrDF_final$teamaml <- NULL 
lrDF_final$teambml <- NULL
lrDF_final$dfa <- NULL
lrDF_final$dateStr <- NULL
names(lrDF_final)

head(lrDF_final)

write.csv(lrDF_final, file = "nba-datawrangle-lrDF.csv")
```
