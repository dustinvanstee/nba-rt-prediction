{"nbformat": 4, "nbformat_minor": 0, "cells": [{"source": "###Imports\n        ", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 32, "metadata": {"collapsed": true}, "outputs": [], "cell_type": "code", "source": "import org.apache.commons.io.IOUtils\nimport java.net.URL\nimport java.nio.charset.Charset\nimport com.databricks.spark.csv\nimport org.apache.spark.sql.SQLContext\nimport org.apache.spark.sql.types.{StructType, StructField, StringType, IntegerType,DoubleType,DateType,TimestampType};\nimport scala.util.matching.Regex\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types.{StructType,StructField,StringType,DoubleType};\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.Column\nimport org.apache.spark.sql.functions.{udf,col,concat,lit,when,ceil}\nimport org.apache.spark.sql._\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.ml.regression.LinearRegression\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.feature.StandardScaler\n"}, {"source": "###Use A Custom Schema To Control Types\n", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 33, "metadata": {"collapsed": true}, "outputs": [], "cell_type": "code", "source": "// This line reads in the file and parses it with a CSV reader\nval sqlContext = new SQLContext(sc)\n// Need this for my shorthand $ notation\nimport sqlContext.implicits._  \n\n// For some reason, the reader below doesn't infer the types properly (all strings) .  Forcing the types here\nval customSchema = StructType(Array(\n    StructField(\"scorea\", IntegerType, true),\n    StructField(\"scoreb\", IntegerType, true),\n    StructField(\"timeleft\", DoubleType, true),\n    StructField(\"teama\", StringType, true),\n    StructField(\"teamb\", StringType, true),\n    StructField(\"scorea-scoreb\", IntegerType, true),\n    StructField(\"scoreb-scorea\", IntegerType, true),\n    StructField(\"pct-complete\", DoubleType, true),\n    StructField(\"pct-left\", DoubleType, true),\n    StructField(\"cf1\", DoubleType, true),\n    StructField(\"cf2\", DoubleType, true),\n    StructField(\"teamaspread\", DoubleType, true),\n    StructField(\"overunder\", DoubleType, true),\n    StructField(\"teambspread\", DoubleType, true),\n    StructField(\"teama_vegas_fscore\", DoubleType, true),\n    StructField(\"teamb_vegas_fscore\", DoubleType, true),\n    StructField(\"key\", StringType, true),\n    StructField(\"fscorea\", DoubleType, true),\n    StructField(\"fscoreb\", DoubleType, true),\n    StructField(\"fscorea-fscoreb\", IntegerType, true),\n    StructField(\"fscoreb-fscorea\", IntegerType, true),\n    StructField(\"away-win\", DoubleType, true),\n    StructField(\"home-win\", DoubleType, true),\n    StructField(\"teama_adj_fscore\", DoubleType, true),\n    StructField(\"teamb_adj_fscore\", DoubleType, true),\n    StructField(\"pfscoreb-pfscorea\", DoubleType, true)\n))"}, {"source": "###Read In CSV File For Logistic Regression\n", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 34, "metadata": {"collapsed": false}, "outputs": [], "cell_type": "code", "source": "val oddsfile = \"swift://notebooks.spark/nba-datawrangle-lrDF.csv\"\nvar logisticDF = sqlContext.read.\n    format(\"com.databricks.spark.csv\").\n    option(\"header\", \"true\"). // Use first line of all files as header\n    option(\"inferSchema\", \"false\"). // Automatically infer data types)\n    option(\"nullValue\", \"empty\").\n    option(\"dateFormat\", \"yyyy-MM-dd\").\n    schema(customSchema).\n    load(oddsfile)\n    \nlogisticDF = logisticDF.withColumn(\"cf3\", $\"pct-left\"*$\"teamaspread\" / 100).\n                        withColumn(\"cf4\", $\"scoreb-scorea\"*$\"scoreb-scorea\"*$\"scoreb-scorea\")\n"}, {"source": "###Inspect the Data", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 35, "metadata": {"collapsed": false}, "outputs": [], "cell_type": "code", "source": "////////////////////////\n// Here make sure the data is read in properly\n//logisticDF.filter($\"timeleft\" < 10).show(50)\nlogisticDF.describe()"}, {"source": "###Function to Create the Model and Train it and Test it", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 36, "metadata": {"collapsed": true}, "outputs": [], "cell_type": "code", "source": "/////////////////////////////////////////////////////////////\n//  Rather than use an ML Pipleline, I created this function so \n// that I could extract/print some intermediate results and\n// debug the model.  \n\ndef trainAndTest( indf : org.apache.spark.sql.DataFrame, featureAryString : Array[String] ) : (org.apache.spark.sql.DataFrame, org.apache.spark.ml.classification.LogisticRegressionModel, Array[Double])  = {\n    println(\"*************************************************\")\n    \n    /////////////////////////////\n    // Split the data into training and test sets\n    \n    val splits = indf.randomSplit(Array(0.7,0.3,0.0), seed = 25L)\n    val trainingdf = splits(0).cache()\n    val testdf = splits(1).cache()\n    \n    println(\"Tranining Samples = \" + trainingdf.count())\n    println(\"Test      Samples = \" + testdf.count())\n    \n\n     /////////////////////////////\n     // use a vector assembler to build features for \n     // logistic model\n     val assembler = new VectorAssembler()\n       .setInputCols(featureAryString)\n       .setOutputCol(\"featuresRaw\")\n\n     val trainingdf2  =  assembler.transform(trainingdf)\n     val testdf2      =  assembler.transform(testdf)\n\n     /////////////////////////////\n     // Standardize the data \n     // logistic model\n    val scaler = new StandardScaler()\n     .setInputCol(\"featuresRaw\")\n     .setOutputCol(\"features\")\n     .setWithStd(false)\n     .setWithMean(false)\n    \n    val scalerModel = scaler.fit(trainingdf2)\n    // Normalize each feature to have unit standard deviation.\n    val trainingdf3 = scalerModel.transform(trainingdf2)\n    val testdf3 = scalerModel.transform(testdf2)\n\n   \n    /////////////////////////////\n    //Logistic Regression Model Setup\n    // Setup some of the configurations for the Logistic regression model ..\n    val lr = new LogisticRegression()\n      .setMaxIter(25)\n      .setRegParam(0.0001)\n      .setElasticNetParam(0.0)\n      .setLabelCol(\"home-win\")\n\n    // Fit the model\n    val lrModel   = lr.fit(trainingdf3)\n\n    println(\"Reg Parameter:    =\" + lrModel.getRegParam)\n    println(\"lrModel.intercept = \" + lrModel.intercept)\n    println(\"lrModel.weights   = \" + lrModel.weights)\n\n    // Save the model for later use ....\n    // Argh ! -> in 1.6.1 api, but not 1.5.2 :(  \n    // lrModel.save(\"modelPath\" )\n    \n    ////  Create a logistic regression summary object ////\n    //val lrSummary = lrModel.summary\n    //println(\"lrSummary.objectiveHistory = \" + lrSummary.objectiveHistory.length)\n    //println(lrSummary.objectiveHistory.deep.mkString(\"\\n\"))\n    ////\n    \n     /////////////////////////////\n     //Generate Predictions\n     // transform is now used in lieu of predict from mllib.  Found this after studying the API for a while\n    val trn_predictions = lrModel.transform(trainingdf3)\n            .withColumn(\"correct\", ($\"home-win\" === $\"prediction\"))\n            .withColumn(\"pct-comp-ceil\", ceil($\"pct-complete\"))\n\n    val predictions = lrModel.transform(testdf3)\n            .withColumn(\"correct\", ($\"home-win\" === $\"prediction\"))\n            .withColumn(\"pct-comp-ceil\", ceil($\"pct-complete\"))\n\n     /////////////////////////////\n     //Evaluate Predictions and Print results\n    \n    val evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"home-win\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"f1\")  // recall / precision also options\n    \n    val trn_tot_f1 = evaluator.evaluate(trn_predictions)\n    val tst_tot_f1 = evaluator.evaluate(predictions)\n    val f1q1 = evaluator.evaluate(predictions.filter($\"pct-complete\" < 25))\n    val f1q2 = evaluator.evaluate(predictions.filter($\"pct-complete\" > 25 && $\"pct-complete\" < 50))\n    val f1q3 = evaluator.evaluate(predictions.filter($\"pct-complete\" > 50 && $\"pct-complete\" < 75))\n    val f1q4 = evaluator.evaluate(predictions.filter($\"pct-complete\" > 75))\n    \n    println(\"Total Train f1 = \" + (trn_tot_f1))\n    println(\"Total Test  f1 = \" + (tst_tot_f1))\n    \n    println(\"Q1 Test f1 = \" + (f1q1))\n    println(\"Q2 Test f1 = \" + (f1q2))\n    println(\"Q3 Test f1 = \" + (f1q3))\n    println(\"Q4 Test f1 = \" + (f1q4))\n\n    val f1Ary = Array(f1q1,f1q2,f1q3,f1q4,tst_tot_f1)\n\n    // return the \n    (predictions,lrModel,f1Ary)\n}"}, {"source": "###Test and Train multiple models", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 37, "metadata": {"collapsed": false}, "outputs": [{"text": "*************************************************\nTranining Samples = 9169\nTest      Samples = 4048\nReg Parameter:    =1.0E-4\nlrModel.intercept = 0.41260820890900873\nlrModel.weights   = [0.18877505797762903]\nTotal Train f1 = 0.7876734627050461\nTotal Test  f1 = 0.7645516405512659\nQ1 Test f1 = 0.6652233914093495\nQ2 Test f1 = 0.6878924759503559\nQ3 Test f1 = 0.7840732373488812\nQ4 Test f1 = 0.9144859475411855\n*************************************************\nTranining Samples = 9169\nTest      Samples = 4048\nReg Parameter:    =1.0E-4\nlrModel.intercept = 0.17507717013282026\nlrModel.weights   = [0.16674937572604415,0.11411501437620475]\nTotal Train f1 = 0.8198671063813032\nTotal Test  f1 = 0.8169695272693457\nQ1 Test f1 = 0.7453483277756455\nQ2 Test f1 = 0.7747614873259977\nQ3 Test f1 = 0.8370955032805536\nQ4 Test f1 = 0.907169459984065\n*************************************************\nTranining Samples = 9169\nTest      Samples = 4048\nReg Parameter:    =1.0E-4\nlrModel.intercept = 0.17183996760200526\nlrModel.weights   = [-0.034776110152298007,0.022592109761735337,0.24208359305268817,4.9571665391790966E-5,0.16204385518333322]\n", "name": "stdout", "output_type": "stream"}], "cell_type": "code", "source": "/////////////////////////////\n// Evaluate 3 different Models\n\nval (prediction_0, model_0, f1m0)   = trainAndTest(logisticDF, Array(\"scoreb-scorea\" ))\nval (prediction_1, model_1, f1m1)   = trainAndTest(logisticDF, Array(\"scoreb-scorea\",  \"teamaspread\" ))\nval (prediction_2, model_2, f1m2)   = trainAndTest(logisticDF, Array(\"scoreb-scorea\",  \"teamaspread\", \"cf1\", \"cf2\", \"cf3\" ))\n\n"}, {"source": "###Examine F1 scores from the models", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 38, "metadata": {"collapsed": false}, "outputs": [], "cell_type": "code", "source": "////////////////////////////////////////////\n// F1 score is a metric used to evaluate different models\n// it runs on a scale from 0 to 1 with the larger value\n// meaning the model performs better\n// F1 score is a combination of precision / recall and\n// helps in situations where outcomes are highly skewed \n// in one direction.  eg 95% samples are wins, 5% are losses\n// in that example, i could make a model that blindly predicts win\n// every time and I would be 95% correct... F1 adjusts for this fact\n// and would penalize me for the false negatives\n\n\n// Build a small dataframe to hold my F1 scores....\nval lblRdd = sc.parallelize( List(\"model0\",\"model1\",\"model2\"),2)\nval errRdd = sc.parallelize( Array(f1m0,f1m1,f1m2),2)\ncase class errData(label: String, q1: Double,q2: Double,q3: Double,q4: Double, tot:Double)\nval test = lblRdd.zip(errRdd)\n\nval errDf = test.map({ \n  case (lbl: String, Array(q1: Double,q2: Double,q3: Double,q4: Double, tot:Double)) => errData(lbl,q1,q2,q3,q4,tot)\n}).toDF(\"model\", \"Q1\",\"Q2\",\"Q3\",\"q4\",\"total\")\n\nerrDf.show()\n//test.take(3)\n\n//going from model0 -> model1 yields a decent improvement, but after that the improvement is marginally better with the extra terms"}, {"source": "###Lets take a look at some of the Errors to see if there is any pattern", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 39, "metadata": {"collapsed": false}, "outputs": [{"text": "+-----+------+-----+------+-------------+-------------+-----------+-------+-------+--------------------+--------+---------------+----------+\n|teama|scorea|teamb|scoreb|     timeleft|pct-comp-ceil|teamaspread|fscorea|fscoreb|         probability|home-win|fscoreb-fscorea|prediction|\n+-----+------+-----+------+-------------+-------------+-----------+-------+-------+--------------------+--------+---------------+----------+\n|  hou|    77|  dal|    73|10.4833333333|           79|       -1.0|   86.0|   88.0|[0.68507285301836...|     1.0|              2|       0.0|\n|  hou|    71|  dal|    70|12.2166666667|           75|       -1.0|   86.0|   88.0|[0.52397604298064...|     1.0|              2|       0.0|\n|  hou|    83|  dal|    82|         5.05|           90|       -1.0|   86.0|   88.0|[0.55029109825172...|     1.0|              2|       0.0|\n|  cle|    31|  chi|    22|         37.6|           22|       -7.5|  102.0|  105.0|[0.86593862015105...|     1.0|              3|       0.0|\n|  hou|    83|  dal|    82|4.61666666667|           91|       -1.0|   86.0|   88.0|[0.55400998790490...|     1.0|              2|       0.0|\n|  cle|    28|  chi|    20|38.4833333333|           20|       -7.5|  102.0|  105.0|[0.85489785525189...|     1.0|              3|       0.0|\n|  hou|    83|  dal|    82|4.21666666667|           92|       -1.0|   86.0|   88.0|[0.55796691817360...|     1.0|              2|       0.0|\n|  cle|    31|  chi|    22|37.1666666667|           23|       -7.5|  102.0|  105.0|[0.86549088265037...|     1.0|              3|       0.0|\n|  cle|    31|  chi|    27|         36.0|           25|       -7.5|  102.0|  105.0|[0.79053173210463...|     1.0|              3|       0.0|\n|  dal|    15|  okc|    11|         42.3|           12|      13.25|   85.0|   84.0|[0.12053476057456...|     0.0|             -1|       1.0|\n|  cle|    84|  chi|    85|10.1833333333|           79|       -7.5|  102.0|  105.0|[0.50723788749091...|     1.0|              3|       0.0|\n|  cle|    31|  chi|    29|35.4333333333|           27|       -7.5|  102.0|  105.0|[0.75147287224741...|     1.0|              3|       0.0|\n|  cle|    82|  chi|    79|         12.0|           75|       -7.5|  102.0|  105.0|[0.71499256148438...|     1.0|              3|       0.0|\n|  dal|    40|  okc|    43|25.9833333333|           46|      13.25|   85.0|   84.0|[0.11696102532961...|     0.0|             -1|       1.0|\n|  cle|    31|  chi|    24|         36.5|           24|       -7.5|  102.0|  105.0|[0.83867186607979...|     1.0|              3|       0.0|\n|  gst|    10|  hou|    16|42.8666666667|           11|       -5.5|   96.0|   97.0|[0.54725016253500...|     1.0|              1|       0.0|\n|  dal|    48|  okc|    51|         21.3|           56|      13.25|   85.0|   84.0|[0.13432910501014...|     0.0|             -1|       1.0|\n|  cle|    31|  chi|    31|        34.75|           28|       -7.5|  102.0|  105.0|[0.70629317772763...|     1.0|              3|       0.0|\n|  gst|    10|  hou|    15|42.8666666667|           11|       -5.5|   96.0|   97.0|[0.57020706086786...|     1.0|              1|       0.0|\n|  gst|    10|  hou|    17|42.3666666667|           12|       -5.5|   96.0|   97.0|[0.52046352485571...|     1.0|              1|       0.0|\n+-----+------+-----+------+-------------+-------------+-----------+-------+-------+--------------------+--------+---------------+----------+\nonly showing top 20 rows\n\n", "name": "stdout", "output_type": "stream"}, {"data": {"text/plain": "Name: Syntax Error.\nMessage: \nStackTrace: "}, "execution_count": 39, "output_type": "execute_result", "metadata": {}}], "cell_type": "code", "source": "prediction_2.filter($\"correct\" === false).select('teama,'scorea,'teamb,'scoreb,$\"timeleft\",$\"pct-comp-ceil\",'teamaspread,'fscorea,'fscoreb,'probability,$\"home-win\",$\"fscoreb-fscorea\",'prediction).\n  filter($\"fscoreb-fscorea\" < 4 && $\"fscoreb-fscorea\" > -4).show(20)\n\nprediction_2.select('teama,'scorea,'teamb,'scoreb,$\"timeleft\",$\"pct-comp-ceil\",'teamaspread,'fscorea,'fscoreb,'probability,$\"home-win\",'prediction).show(5)\n\n//val (prediction_4, model_4, f1m4)   = trainAndTest(logisticDF, Array(\"scoreb-scorea\",  \"teamaspread\", \"cf1\", \"cf2\", \"cf3\",\"cf4\" ))\n\n// Some errors due to \n//   early in game ....\n//   close scores at the end\n//   some games the spread strongly effects game at the end... mabye scale that somehow by time left ?\n//   teams that had an early lead, even though not favored did end up winning.  maybe add a scorediff^2"}, {"source": "###Plot Correct / Incorrect predictions as a function of pct-Complete (REMOVE)", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "###Logistic Analysis And Explanation\n\n    Complex Model 2 Discussion\n    When the logistic regression model is trained, the weights corresponding to each feature are optimized to minimize the error of the predictions.  Below\n    are the weight from the final model that was trained with 5 features.\n\n               scoreb-scorea         teamaspread          custom_feature_1    custom_feature_2      custom_feature_3\n    weights =  [-0.034776110152298007,0.022592109761735337,0.24208359305268817,4.9571665391790966E-5,0.16204385518333322]\n\n    Interpretting weights can be tricky, especially if input features are functions of each other (ie, if one feature changes, it implies another feature changes)\n    \n    Lets look at just the away team spread, as this feature is not a function of any other feature.\n    \n    The away spread weight is 0.02259.  If the spread increases by 1, then the probability of the away team winning is \n    \n    \n$$e^{0.02259} = 1.023$$ \n    \n    This means that there is a 2.3% relative increase in the probablity the home team will win for every one point change in away team spread.\n    ", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "###Function to predict new examples (Requires debug, potentially REMOVE)", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 40, "metadata": {"collapsed": false}, "outputs": [], "cell_type": "code", "source": "import org.apache.spark.sql._\n// These is a helper function that converts an 'Any(Int)' type to a Double or Any(Double) to a Double\nval ai2d : (Any => Double) = (in:Any) => in.asInstanceOf[java.lang.Integer].doubleValue\nval ad2d : (Any => Double) = (in:Any) => in.asInstanceOf[java.lang.Double]\n\n////////////////////////////////////////////////////////////\n// These were a couple custom UDF's I needed to cleanse the data \n// and also to add a few features based on a proprietary way of combining\n// the score with the time left.\n\n// Date Logic to adjust for games that finish on the day after ....\n// This is due to not having a great key to join my tables ...\nval datecrossregex = new Regex(\"^0[0-3]\")\nval dateadjust : ((String, String) => String) = (datein, tsin ) => {\n    val datetest =  datecrossregex.findFirstIn(tsin)\n    val dateary = datein.split(\"-\")\n    val rv = datetest match {\n      case Some(s) => { \n         val day = \"%02d\".format(dateary(2).toInt -1)\n         val newdate = dateary(0) + \"-\" + dateary(1) + \"-\" + day  \n         newdate\n      }\n      case None => datein\n    }\n    rv.asInstanceOf[String]\n}\nval dateadjustudf = udf(dateadjust)\n\n// UDFs to create some extra features ... this one is for an experiemental combination of Time left and Score difference.  \n// Made this via intuition.  This can be extended to add other custom features\n//val crossOverTime = 8\n//val exponentScaler = 0.5\nval scoredivtimeXform: ((Double,Double,Double,Double) => Double) = (sd:Double, tl:Double, co:Double, exp:Double) => {\n    val scaler = 1 / Math.pow( (tl / co) + 0.01 , exp)\n    sd * scaler\n}\nval scoredivtimeUdf = udf(scoredivtimeXform)\n\n\ndef getPrediction_model2(teama : String  , scorea : Int , teamb : String , scoreb : Int,  timeleft : Double, teamaspread : Double, model : org.apache.spark.ml.classification.LogisticRegressionModel) : Unit = {\n\n  //model2 features = \"scoreb-scorea\",  \"teamaspread\", \"cf1\", \"cf2\", \"cf3\"\n  val sd = scoreb-scorea\n  val ts = teamaspread\n  val pctleft = timeleft / 48.0;\n  \n  val cf1 = scoredivtimeXform(sd.toDouble, pctleft.toDouble, 25.0, 0.5)\n  val cf2 = scoredivtimeXform(sd.toDouble, pctleft.toDouble, 2.0, 1.3)\n  val cf3 = pctleft*ts/100;\n  val lp = LabeledPoint(0.0,Vectors.dense(sd,teamaspread,cf1,cf2,cf3))\n\n  val single = Seq(lp).toDF(\"label\",\"features\")\n  val result = model.transform(single)\n  val rv = result.select($\"prediction\").head(1)\n  val prb = result.select($\"probability\").head(1)\n\n  val rv1 = ad2d(rv(0)(0))\n  val prb1 = prb(0)(0)\n  //println(\"dbg : sdt =\" + sdt)\n  println(teama + \"(away) vs \" + teamb + \"(home)\")\n  println(\"Spread(HomeTeam) : \" + teamaspread + \" (+ means home team is not favored)\")\n  println(\"Time Left        : \" + timeleft)\n  val winner = {if (rv1 == 1) teamb else teama}\n  println(\"Predicted Winner : \" + winner + \" Probablity : \" + prb1)\n}\n"}, {"source": "###Simple Predictor based on a new Example ....", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 41, "metadata": {"collapsed": false}, "outputs": [{"text": "lac(away) vs por(home)\nSpread(HomeTeam) : -8.0 (+ means home team is not favored)\nTime Left        : 20.0\nPredicted Winner : por Probablity : [9.44528374407261E-6,0.999990554716256]\n", "name": "stdout", "output_type": "stream"}], "cell_type": "code", "source": "// Arguments : Home Team, Home Team Score, Home Team, Home Team Score, Timeleft, Away Team Spread, Model)\ngetPrediction_model2(\"lac\",88, \"por\", 96, 20.0, -8.0, model_2)"}, {"source": "### Now lets implement Model2 in our Node.js web app!  See README for more details.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "cell_type": "code", "source": ""}], "metadata": {"language_info": {"name": "scala"}, "kernelspec": {"language": "scala", "display_name": "Scala 2.10", "name": "spark"}}}