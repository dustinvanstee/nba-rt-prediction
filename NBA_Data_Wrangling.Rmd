---
title: "NBA_Data_Wrangling"
author: "Catherine C."
date: "September 14, 2016"
output: html_document
---

# Import libraries
> Note: run *intall.packages()* before loading the packages.
```{r}
# general data maniputlation: summarise, filter, etc.
#install.packages("dplyr")
library(dplyr)

#install.packages("plyr")
library(plyr)

# manipulation of date/time data
#install.packages("chron")
library(chron)

# interactive plots
#install.packages("scatterD3")
library(scatterD3)

#install.packages("plotly")
library(plotly)

```

***

# Inspect Score Data
```{r}
nba_scores <- "/home/rstudio/NBA/scores_nba.test.dat"
lines <- readLines(nba_scores)
head(lines)
```

***

# Load in NBA Score Data Sets
```{r}
# turn the .dat file to dataframe
nba_scores_DF <- as.data.frame(do.call(rbind, strsplit(lines, ",")), stringsAsFactors=FALSE)

# Since I don't have a header in the data set, I want to specify the column metadata
colnames(nba_scores_DF) <- c("dateOrig","ts","teamlonga", "scorea", "teamlongb", "scoreb", "timestring", "timeleft", "gameid")
nba_scores_DF2 <- transform(nba_scores_DF, dateOrig = as.Date(dateOrig),
                            ts = as.character(ts),
                            teamlonga = as.character(teamlonga),
                            scorea = as.numeric (scorea),
                            teamlongb = as.character(teamlongb),
                            scoreb = as.numeric (scoreb),
                            timestring = as.character(timestring),
                            timeleft = as.numeric(timeleft),
                            gameid = as.character(gameid))
```

***

# Inspect Historical score data

> This data is the raw input that contains a record for each update of the game.
Data has some errors and redundancies that must be removed.  Will discuss that as we go along ....
in particular, we need to seperate the in game scores and the final score and re-merge them for our model

```{r}
# NAs are introduced because the raw data has invalid data points, so remove these observations
rtscoresAndFinalDF <- na.omit(nba_scores_DF2)
dim(rtscoresAndFinalDF) #16746     9

head(rtscoresAndFinalDF)

head(filter(rtscoresAndFinalDF, grepl("FINAL", timestring)))

head(filter(rtscoresAndFinalDF, grepl("1ST", timestring)))

```
***

# UDFs for creating extra columns in real time data frame

>  These were a couple custom UDF's I needed to cleanse the data and also to add a few features based on a proprietary way of combining the score with the time left.

```{r}
# Function to turn long team name to short
teamMap <- function(x) {
  tnames <- data.frame(
    long = as.factor(c("Atlanta", "Boston", "Brooklyn", "Charlotte", "Chicago", 
                       "Cleveland", "Dallas", "Denver", "Detroit", "Golden State", 
                       "Houston","Indiana", "LA Clippers", "LA Lakers", "Memphis", 
                       "Miami", "Milwaukee", "Minnesota", "New Orleans", "New York",
                       "Oklahoma City", "Orlando", "Philadelphia", "Phila.", "Phoenix",
                       "Portland",  "Sacramento", "San Antonio", "Toronto", "Utah", "Washington")),
    short = as.factor(c("atl", "bos", "bkn", "cha", "chi",
                        "cle", "dal", "den", "det", "gst",
                        "hou", "ind", "lac", "lal", "mem",
                        "mia", "mil", "min", "nor", "nyk",
                        "okc", "orl", "phi", "phi", "pho",
                        "por", "sac", "san", "tor", "uta", "wsh"))
  )
  df_x <- data.frame(long=x)
  short <- tnames$short[match(df_x$long, tnames$long)]
  return(short)
  
}

# Function to convert 3-character month to 2-digit numeric month
monthMap <-function(x) {
  a <-data.frame(
    str = as.factor(c("Jan", "Feb", "Mar", "Apr", "May", 
                      "Jun", "Jul", "Aug", "Sep", "Oct", 
                      "Nov", "Dec")),
    num = as.factor(c("01", "02", "03", "04", "05",
                      "06", "07", "08", "09", "10",
                      "11", "12"))
  )
  df_x <- data.frame(str=x)
  num <- a$num[match(df_x$str, a$str)]
  return(num) 
}

# Date Logic to adjust for games that finish on the day after ....
# This is due to not having a great key to join my tables ...
dateadjustudf <- function(datein, tsin){
                   newdate <- c()
                   for (i in 1:length(tsin)){
                      if (grepl("^0[0-3]", tsin[i])) {
                          newdate[i] = datein[i] - 1
                      } else {
                          newdate[i] = datein[i]
                      }
                    }
                   return(newdate)
                  }

# UDFs to create some extra features ... this one is for an experiemental combination of Time left and Score difference.  
# Made this via intuition.  This can be extended to add other custom features
# val crossOverTime = 8
# val exponentScaler = 0.5
# There is no need to create UDFs here

```

***

# Preproces the Real Time and Final Score Data . Add some useful columns to the data set
> Here I create some extra columns for later use. 
```{r}
# Remove Overtime games from this analysis
rtscoresAndFinalDF <- filter(rtscoresAndFinalDF, !grepl(".*OT.*", timestring))
#16626

# Create short 3 character team names
rtscoresAndFinalDF$teama <- teamMap(rtscoresAndFinalDF$teamlonga)
rtscoresAndFinalDF$teamb <- teamMap(rtscoresAndFinalDF$teamlongb)

# Add a score differential Column 
rtscoresAndFinalDF$scorea_scoreb <- rtscoresAndFinalDF$scorea - rtscoresAndFinalDF$scoreb

# Transform the Date.  This is for games that spanned multiple days and gave me a headache.  
# Games adjusted to the day they started on.
rtscoresAndFinalDF$date <-  dateadjustudf(rtscoresAndFinalDF$dateOrig, rtscoresAndFinalDF$ts)
rtscoresAndFinalDF$date <- as.Date(rtscoresAndFinalDF$date, origin = "1970-01-01")

# Create a Key for me to use to join with odds data later.  Key = date.teama.teamb
for (i in 1:nrow(rtscoresAndFinalDF)){
  rtscoresAndFinalDF$key[i] <- paste0(rtscoresAndFinalDF$date[i], ".", rtscoresAndFinalDF$teama[i], ".", rtscoresAndFinalDF$teamb[i])
}
```

***
# Separate The Real Time And Final Data From One Common Dataframe To Two Dataframes
> Currently based on the way the data was sampled, both real time scores and final scores are written as seperate records to the same file. I need to pull these apart, and then join the dataframes so that I have a real time score and features and know if the game was won or lost ....

```{r}
# Create Final Score DF
# Note a shortcut for repeating the dataframe within the filter is to use a $df.filter(df("foo").contains ... is equiv to df.filter($"foo".contains)
finalscoresDF <- filter(rtscoresAndFinalDF, grepl("FINAL", timestring))

# Rename some columns so that join later doesnt have name overlaps
finalscoresDF$fscorea <- finalscoresDF$scorea
finalscoresDF$fscoreb <- finalscoresDF$scoreb

# Create final score difference
finalscoresDF$fscorea_fscoreb <- finalscoresDF$fscorea - finalscoresDF$fscoreb
finalscoresDF$fscoreb_fscorea <- finalscoresDF$fscoreb - finalscoresDF$fscorea


# Add a Win/loss column Win = 1, Loss = 0
for (i in 1 : nrow(finalscoresDF)){
  if (finalscoresDF$fscorea_fscoreb[i] > 0){
    finalscoresDF$home_win[i] <- 0
    finalscoresDF$away_win[i] <- 1
  } else {
    finalscoresDF$home_win[i] <- 1
    finalscoresDF$away_win[i] <- 0
  }
}


#################################################################################################################
# Create Real time score DF and more wrangling

# Remove Halftime records and these other cases as my datasource doesnt always change the quarter well
# as this particular case isn't handled well... (for now)
rtscoresDF <- filter(rtscoresAndFinalDF, !grepl('HALF', timestring), !grepl('FINAL', timestring),
                   timestring != "(12:00 IN 1ST)" ,
                   timestring != "(12:00 IN 2ND)" , 
                   timestring != "(12:00 IN 3RD)" ,
                   timestring != "(12:00 IN 4TH)" ,  
                   timestring != "(END OF 1ST)" ,
                   timestring != "(END OF 2ND)" , 
                   timestring != "(END OF 3RD)" ,
                   timestring != "(END OF 4TH)" )


# Create real time score difference
rtscoresDF$scorea_scoreb <-  rtscoresDF$scorea - rtscoresDF$scoreb
rtscoresDF$scoreb_scorea <-  rtscoresDF$scoreb - rtscoresDF$scorea


# Create a game PCT complete and PCT left indictor
rtscoresDF$pct_complete <- (((rtscoresDF$timeleft * -1) + 48 )/48.0)*100
rtscoresDF$pct_left <- 100 - rtscoresDF$pct_complete

# Create a unique feature. Idea here is that I have intuition that timeleft and score difference are a strong predictor when combined
rtscoresDF$cf1 <- (1/((rtscoresDF$pct_left/25 + .01)^.5)) * rtscoresDF$scoreb_scorea
rtscoresDF$cf2 <- (1/((rtscoresDF$pct_left/2.0 + .01)^1.3))*rtscoresDF$scoreb_scorea

```

***

# Custom Feature Explanation

> After building my initial model, I noticed that the logistic model was adjusting the probabilities well at the end of the games. I had some examples where I had 0 time left in the game, and yet the logistic model was giving a 70% chance of victory for a team. I speculated this was due to the fact that my original features were not fitting the end of game very well. To fix this, I created a spreader custom feature that basically takes the score difference and amplifies it as the score nears the end of the game. This way this feature is very predictive at the end of games and can help adjust the probablities to be more certain at the end of games.



# Show effect of custom spreader feature 
```{r}
# subset a dataframe for scatterplot
spreader <- filter(rtscoresDF, pct_complete < 95)

# draw interactive scatter plot
scatterD3(x = spreader$pct_complete, y = spreader$scoreb_scorea, col_var = spreader$key)
```

***

# Inspect Custom features ...
```{r}
scatterD3(x = spreader$pct_complete, y = spreader$cf2, col_var = spreader$key)
```
***

# Lets Take A Look Of What We Have For The Two Dataframes We Just Wrangled
```{r}
# Some Printouts .....
print("final scores data frame")
head(finalscoresDF)
paste0("Total Games = ", nrow(finalscoresDF))
print("real time scores data frame")
head(rtscoresDF)
paste0("Total Number of rt score records = ", nrow(rtscoresDF))
```


# Inspect Odds Data
> How to Read the Raw Odds data


    
    Example Golden State -12.5 O (207.0) -125.0 | Detroit 12.5 U (207.0) 145.0
    The away team is listed first, and the home team is second
    Here Golden State is a 12.5 pt favorite to win.  The over under is in parentheses (207) and is the 50/50 line between teams sum of scores
    being above/below that line.  
    Finally the -125 / +145 numbers are whats known at the moneyline odds. 
        A negative number means you need to bet 125$ to get a 100$ payout
        A positive number means you need to bet 100$ to get a 145$ payout
***

# load in odds data
```{r}
nba_odds <- "/home/rstudio/NBA/nbaodds_042516.xml"
xml <- as.list(readLines(nba_odds))
head(xml)

# use regular expression to catch info we need
odds <- lapply(xml, function(x) substr(x, regexpr(">", x) + 1, regexpr("/", x) - 2))
odds_split <- lapply(odds, function(x) unlist(strsplit(x, " ")))

# get teamlonga
teamlonga_0 <- lapply(odds_split, function(x) paste(x[1], x[2]))
teamlonga <- lapply(teamlonga_0, function(x){
  if (regexpr("[0-9|-]", x) > -1) {
    substr(x, 1, regexpr("[0-9|-]", x)-2) 
  } else{
    x 
  }
})

# get teamlongb
teamlongb_0 <- lapply(odds_split, function(x) paste(x[7],x[8], x[9]))
teamlongb_1 <- lapply(teamlongb_0, function(x){
  if (regexpr("[0-9]", x) > -1) {
    substr(x, regexpr("[A-Za-z]", x), regexpr("[0-9-]", x)-2) 
  } else{
    x 
  }
})

teamlongb <- lapply(teamlongb_1, function(x){
  if (regexpr("|", x) > -1){
    substr(x, regexpr("[A-Za-z]", x), nchar(x))
  } else {
    x
  }
})

# teamaspread
teamaspread_0 <- lapply(odds, function(x){
  substr(x, regexpr("[0-9-]",x), regexpr("[0-9-]",x)+4)
})

teamaspread <- lapply(teamaspread_0, function(x){
  if (regexpr("[ ]", x) > 0){
    substr(x, 1, regexpr("[ ]", x)-1)
  } else {
    x
  }
})

# overunder
overunder <- lapply(odds, function(x){
  substr(x, regexpr("[(]", x) + 1, regexpr("[)]", x) - 1)
})

# teamaml
teamaml <- lapply(odds, function(x){
  substr(x,regexpr("[)]", x) + 2, regexpr("[|]", x) - 2 )
})

# teambml
teambml <- lapply(odds, function(x){
  substr(x, gregexpr("[)]", x)[[1]][2]+2, gregexpr("[(]", x)[[1]][3]-2)
})


#get date
dateStr <- lapply(odds, function(x){
  month <- substr(x, gregexpr("[(]", x)[[1]][3]+1, gregexpr("[(]", x)[[1]][3]+3)
  month_num <- monthMap(month)
  date <- substr(x, gregexpr("[(]", x)[[1]][3]+5, gregexpr("[(]", x)[[1]][3]+6)
  year <- substr(x, gregexpr("[(]", x)[[1]][3]+9, gregexpr("[(]", x)[[1]][3]+12)
  paste0(year, "-", month_num, "-", date)
})

# get short team names
teama <- lapply(teamlonga, teamMap)
teamb <- lapply(teamlongb, teamMap)

# bind all column together into dataframe

oddsDF <- do.call(rbind, Map(data.frame, teamlonga=teamlonga, teama=teama, teamlongb=teamlongb, teamb=teamb, teamaspread=teamaspread, overunder=overunder, teamaml=teamaml, teambml=teambml, dateStr=dateStr))

# change to right data type and create a key for join later
oddsDF$teamaspread <- as.numeric(as.character(oddsDF$teamaspread))
oddsDF$overunder <- as.numeric(as.character(oddsDF$overunder))
oddsDF$teamaml <- as.numeric(as.character(oddsDF$teamaml))
oddsDF$teambml <- as.numeric(as.character(oddsDF$teambml))

oddsDF$teama <- as.character(oddsDF$teama)
oddsDF$teamb <- as.character(oddsDF$teamb)
oddsDF$key <- paste0(oddsDF$dateStr, ".", oddsDF$teama, ".", oddsDF$teamb)
dim(oddsDF) #161  10

# add the groupby and average below because I was getting the game odds over multiple days, and it was adding noise to the analysis

oddsDF2 <- ddply(oddsDF, c("key", "teamlonga", "teamlongb", "teama", "teamb", "dateStr"), summarise,
               teamaspread = mean(teamaspread),
               overunder = mean(overunder),
               teamaml = mean(teamaml),
               teambml = mean(teambml))

# Create a few new columns for later analysis

oddsDF2$teambspread <- oddsDF2$teamaspread * -1

oddsDF2$teama_vegas_fscore <- (oddsDF2$overunder / 2.0) - (oddsDF2$teamaspread / 2.0)

oddsDF2$teamb_vegas_fscore <- (oddsDF2$overunder / 2.0) + (oddsDF2$teamaspread / 2.0)

```

***

# Inspect some of the Odds Data
```{r}
head(oddsDF2)
paste("total home teams = ", length(unique(oddsDF2$teama)))
paste("total away teams = ", length(unique(oddsDF2$teamb)))
paste("total games collected = ", nrow(oddsDF2))
```

***

# Avg Team Away Game Spread -  ( hint < 0 means favorite)

> Here we are averaging the away spread per team.  If the bar is above the zero line, then the team is an underdog, and under the line the team is the favorite. 8 of the 32 teams were favorites on the road... and they are the likely suspect including CLE/GST/OKC

```{r}
# visualize away spread data
avg_away_spread <- ddply(oddsDF2, c("teamlonga", "teamlongb"), summarise,
                         awayspread_avg_teamaspread = mean(teamaspread),
                         awayspread_avg_teambspread = mean(teambspread))

# away spread group by teama
away_spread_teama <- ddply(avg_away_spread, c("teamlonga"), summarise,
                           teamaspread = mean(awayspread_avg_teamaspread))
# order by teama
away_spread_teama$teamlonga <- as.character(away_spread_teama$teamlonga)
away_spread_teama <- away_spread_teama[order(away_spread_teama$teamlonga), ]

# barchart
p <- plot_ly(
  x = away_spread_teama$teamlonga,
  y = away_spread_teama$teamaspread,
  type = "bar")
p
````

***

# Avg Home Team Game Spread - (Hint > 0  means underdog)
> Here we are averaging the home spread per team.  If the bar is above the zero line, then the team is an underdog, and under the line the team is the favorite. Note here that the home teams are favored much more, with the usual suspects having a very large advantage (SAN/GST/OKC)

```{r}
# spread group by teamb
away_spread_teamb <- ddply(avg_away_spread, c("teamlongb"), summarise,
                           teambspread = mean(awayspread_avg_teambspread))
# order by teamb
away_spread_teamb$teamlongb <- as.character(away_spread_teamb$teamlongb)
away_spread_teamb <- away_spread_teamb[order(away_spread_teamb$teamlongb), ]

p <- plot_ly(
  x = away_spread_teamb$teamlongb,
  y = away_spread_teamb$teambspread,
  type = "bar")
p

```

***

# Join odds and final scores data.
```{r}
# Here is where we join the Odds/Realtime scores/ Final Scores into one wholistic data set as input for Logistic Machine Learning

# Create a smaller Final Score Dataframe.  Just keep the key, final score a and b, the win/loss indicator
finalslicedscoresDF <- finalscoresDF[c("key","fscorea", "fscoreb", "fscorea_fscoreb", "fscoreb_fscorea", "away_win", "home_win")]

# First Join the 2 smallest data frames ... odd and final.
gameDF <- merge(finalslicedscoresDF, oddsDF2, by = "key")
gameDF$teamlonga <- NULL
gameDF$teamlongb <- NULL
gameDF$teama <- NULL
gameDF$teamb <- NULL

# Print Out the Game Dataframe ... notice we have the odds data merged with the win loss data ....
print("gameDF")
head(gameDF)
paste("total games collected:", nrow(gameDF)) #103

```

*** 
# Lets see if there are some correlations ... Spread vs Final Score Difference 
```{r}
# Here we show that the better a team is (negative spread, the more they are likely to win ...)

#Here the spread at the start of the game is a decent predictor regarding the end result

# Final Score Difference vs Spread  
# Top Left indicates teams with a large pos spread will lose by a wider margin
# the line should approx pass through 0,0
# lower Right indicates teams with large neg spread will win by a wider margin 

# The logistic and linear models we build will quantify this for us later!

scatterD3(x = gameDF$fscoreb_fscorea, y = gameDF$teamaspread)
```

***

# Home / Away sensitivity to Point Spread 
```{r}
# Here we can show another weak correlation of the vegas overunder/spread to the actual final outcome.
# vegas_fscore was calculated by taking overunder/2 +- the spread/2 to get a projection of
# the home/away teams score
# Here if the prediction and data were perfectly correlated, we would pass through the
# y=x line.  in general we follow that path
# we will see how this term plays when we dig into the linear model
# here only home team is shown, but same trend holds for away team

scatterD3(x = gameDF$teamb_vegas_fscore, y = gameDF$fscoreb)
```

***

# Join The Game Dataframe With The Real Time Score Dataframe
```{r}
# This is the bigger merge.  Merging the odds/final score data with the real time indicators ...
lrDF <- merge(gameDF, rtscoresDF, by = "key")
print("lrDF : Logistic Regression Data Frame")
head(lrDF)

paste("total data points collected:", nrow(lrDF)) #13412

```

# Add a Few More Features
```{r}

# Add an overunder/spread adjusted projection as points are scored during the game
# I found this is a strong indicator
lrDF$teama_adj_fscore <- ((lrDF$pct_complete  * -1)/100 + 1) * lrDF$teama_vegas_fscore + lrDF$scorea
lrDF$teamb_adj_fscore <- ((lrDF$pct_complete  * -1)/100 + 1) * lrDF$teamb_vegas_fscore + lrDF$scoreb
lrDF$pfscoreb_pfscorea <- lrDF$teamb_adj_fscore - lrDF$teama_adj_fscore
```

***

# Filter Out some Data due to data quality
```{r}
# There is an issue with the data I had captured.  When a quarter transitions from 1st->2nd (etc,etc), sometime the timestring doesn't get updated properly.  Since I used the timestring to calculate the timeleft in the game, I would get some rogue data points.  
# Example, after 1 min in a game, something the two teams would have scores in the 20's, because it was really at 11 mins in the second quarter.  
# My solution was to use the final score sum, and then just scale that down to the time left in the game.  I would then compare to the sum of scores i had, and if it was significantly higher, I would remove them.  I did this by visual inspection ... 
# dfa = departure_from_avg

lrDF$dfa <- (lrDF$fscorea + lrDF$fscoreb)/48 * (lrDF$timeleft * -1 + 48) - (lrDF$scorea + lrDF$scoreb)
lrDF_filtered <- filter(lrDF, dfa > -30)
```

***

# Lets Look at some stats from logistic Regression dataframe
```{r}

summary(lrDF_filtered)
```

# Visualize some of our Time Series Data. ...
```{r}
# here we can see the trajectory of some of the games .....    
# upper left beginning ... upper right (win), lower right (loss)
# cool visual .... gives an idea about how the games flow
tsplot <- filter(lrDF_filtered, grepl("cle", key) | grepl("gst", key))

scatterD3(x = tsplot$pct_complete, y = tsplot$scoreb_scorea, col_var = tsplot$key)
```

***

# Samples per Game Visualization - Data Quality check
```{r}

DQ_check <- ddply(lrDF_filtered, c("key"), summarise,
                      N = length(key))
# order by N
DQ_check <- DQ_check[order(DQ_check$N),]

p <- plot_ly(
  x = DQ_check$Key,
  y = DQ_check$N,
  type = "bar")
p
```

***

# Save Out Dataframe For Further Analysis with Logistic and Linear Regression Notebooks
```{r}
# Wanted to save out the dataset at this point as I will branch into seperate work efforts for a Logistic/Linear model building
# drop some columns as we move on to next step !!

lrDF_final <- lrDF_filtered
lrDF_final$dateOrig <- NULL
lrDF_final$ts <- NULL
lrDF_final$teamlonga.x <- NULL
lrDF_final$teamlongb.x <- NULL
lrDF_final$teamlonga.y <- NULL
lrDF_final$teamlongb.y <- NULL
lrDF_final$timestring <- NULL
lrDF_final$gameid <- NULL
lrDF_final$teamaml <- NULL 
lrDF_final$teambml <- NULL
lrDF_final$dfa <- NULL
lrDF_final$teama.y <- NULL
lrDF_final$teamb.y <- NULL
lrDF_final$dateStr <- NULL
names(lrDF_final)[c(8, 9)] <- c("teama", "teamb")

head(lrDF_final)

write.csv(lrDF_final, file = "nba-datawrangle-lrDF.csv")
```
